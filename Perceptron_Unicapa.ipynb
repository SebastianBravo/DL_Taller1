{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea39fb3",
   "metadata": {},
   "source": [
    "# Perceptrón Unicapa (TLU) — Clasificación binaria de género en Twitter\n",
    "\n",
    "**Taller 1 — Deep Learning (2026-10)**\n",
    "\n",
    "**Modelo:** Perceptrón Unicapa con función escalón (Threshold Logic Unit)\n",
    "\n",
    "**Objetivo:** Clasificar usuarios de Twitter como `male (0)` o `female (1)`.\n",
    "\n",
    "Los datos ya fueron preprocesados en `Taller1DL.ipynb` (secciones 1-5) y se cargan desde archivos `.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365747a",
   "metadata": {},
   "source": [
    "## 1. Carga de datos preprocesados\n",
    "\n",
    "Los archivos `.npy` contienen las matrices ya:\n",
    "- Imputadas (nulos tratados)\n",
    "- Escaladas (StandardScaler para numéricas)\n",
    "- Codificadas (OneHotEncoder para categóricas)\n",
    "- Particionadas (60% train, 20% val, 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802428a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "  DIMENSIONES DE LOS DATOS\n",
      "==================================================\n",
      "  Train: X=(7736, 9), y=(7736,)\n",
      "  Val:   X=(2579, 9),   y=(2579,)\n",
      "  Test:  X=(2579, 9),  y=(2579,)\n",
      "\n",
      "  Número de features: 9\n",
      "  Clases únicas: [0 1]  (0=male, 1=female)\n",
      "\n",
      "  Train → male: 3716, female: 4020\n",
      "  Val   → male: 1239,   female: 1340\n",
      "  Test  → male: 1239,  female: 1340\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar matrices preprocesadas generadas en Taller1DL.ipynb\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\")\n",
    "X_test  = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_val   = np.load(\"y_val.npy\")\n",
    "y_test  = np.load(\"y_test.npy\")\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(\"=\"*50)\n",
    "print(\"  DIMENSIONES DE LOS DATOS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Val:   X={X_val.shape},   y={y_val.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape},  y={y_test.shape}\")\n",
    "print(f\"\\n  Número de features: {X_train.shape[1]}\")\n",
    "print(f\"  Clases únicas: {np.unique(y_train)}  (0=male, 1=female)\")\n",
    "\n",
    "# Verificar distribución en cada conjunto\n",
    "print(f\"\\n  Train → male: {np.sum(y_train==0)}, female: {np.sum(y_train==1)}\")\n",
    "print(f\"  Val   → male: {np.sum(y_val==0)},   female: {np.sum(y_val==1)}\")\n",
    "print(f\"  Test  → male: {np.sum(y_test==0)},  female: {np.sum(y_test==1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c51c5",
   "metadata": {},
   "source": [
    "## 2. ¿Qué es el Perceptrón Unicapa?\n",
    "\n",
    "El **perceptrón** es el modelo de red neuronal más simple que existe. Fue propuesto por Frank Rosenblatt en 1958.\n",
    "\n",
    "### Arquitectura:\n",
    "```\n",
    "x₁ ──→ w₁ ──┐\n",
    "x₂ ──→ w₂ ──┤\n",
    "x₃ ──→ w₃ ──┼──→ Σ(wᵢxᵢ) + b ──→ f(z) ──→ ŷ ∈ {0, 1}\n",
    " ⋮           │\n",
    "xₙ ──→ wₙ ──┘\n",
    "```\n",
    "\n",
    "### Componentes:\n",
    "- **Entradas (x):** Las features preprocesadas (N variables)\n",
    "- **Pesos (w):** Un peso por cada feature, aprendido durante el entrenamiento\n",
    "- **Bias (b):** Un sesgo que desplaza la frontera de decisión\n",
    "- **Función de activación:** Escalón (step / TLU)\n",
    "\n",
    "### Función escalón (Threshold Logic Unit):\n",
    "\n",
    "$$\\hat{y} = \\begin{cases} 1 & \\text{si } \\sum_{i=1}^{n} w_i x_i + b \\geq 0 \\\\ 0 & \\text{si } \\sum_{i=1}^{n} w_i x_i + b < 0 \\end{cases}$$\n",
    "\n",
    "### Regla de actualización del perceptrón:\n",
    "Para cada muestra mal clasificada:\n",
    "$$w_i \\leftarrow w_i + \\eta \\cdot (y - \\hat{y}) \\cdot x_i$$\n",
    "\n",
    "Donde $\\eta$ es la **tasa de aprendizaje**.\n",
    "\n",
    "### Limitación clave:\n",
    "Solo puede resolver problemas **linealmente separables**. No puede aprender fronteras de decisión curvas o complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407e4be",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Perceptrón\n",
    "\n",
    "Usamos `sklearn.linear_model.Perceptron` que implementa exactamente el algoritmo del perceptrón clásico:\n",
    "- **Sin capas ocultas** (unicapa)\n",
    "- **Función escalón** como activación\n",
    "- **Regla del perceptrón** para actualizar pesos\n",
    "\n",
    "### Hiperparámetros:\n",
    "| Parámetro | Valor | Descripción |\n",
    "|---|---|---|\n",
    "| `max_iter` | 1000 | Máximo de pasadas completas por los datos (épocas) |\n",
    "| `eta0` | 0.01 | Tasa de aprendizaje (qué tanto ajusta los pesos) |\n",
    "| `tol` | 1e-3 | Si la pérdida no mejora más que esto, para |\n",
    "| `early_stopping` | True | Detiene si no mejora en validación interna |\n",
    "| `n_iter_no_change` | 10 | Épocas consecutivas sin mejora para detenerse |\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf9ce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "  MODELO ENTRENADO\n",
      "==================================================\n",
      "  Épocas ejecutadas:    13\n",
      "  Número de features:   9\n",
      "  Shape de pesos (w):   (1, 9)\n",
      "  Bias (b):             0.010000\n",
      "  Pesos ≠ 0:            8 de 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# ============================================\n",
    "# 3) Crear y entrenar el Perceptrón\n",
    "# ============================================\n",
    "\n",
    "perceptron = Perceptron(\n",
    "    max_iter=1000,           # Máximo de épocas\n",
    "    eta0=0.01,               # Tasa de aprendizaje\n",
    "    tol=1e-3,                # Tolerancia para convergencia\n",
    "    random_state=42,         # Reproducibilidad\n",
    "    early_stopping=True,     # Parar si no mejora\n",
    "    validation_fraction=0.2, # 20% del train para validación interna\n",
    "    n_iter_no_change=10      # Épocas sin mejora para parar\n",
    ")\n",
    "\n",
    "# Entrenar SOLO con datos de entrenamiento\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Información del modelo entrenado\n",
    "print(\"=\"*50)\n",
    "print(\"  MODELO ENTRENADO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Épocas ejecutadas:    {perceptron.n_iter_}\")\n",
    "print(f\"  Número de features:   {X_train.shape[1]}\")\n",
    "print(f\"  Shape de pesos (w):   {perceptron.coef_.shape}\")\n",
    "print(f\"  Bias (b):             {perceptron.intercept_[0]:.6f}\")\n",
    "print(f\"  Pesos ≠ 0:            {np.sum(perceptron.coef_ != 0)} de {perceptron.coef_.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
